<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">p;'?
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Matrix Calculus | Machine Learning | Infinite Maths</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css">
    <style>
        /* Inherit all styles from index.html */
        body {
            background: linear-gradient(135deg, 
                #fbc2eb 0%,   /* Lighter purple */
                #afdcec 20%,   /* Lighter blue */
                #ccffff 35%,   /* Even lighter blue */
                #ffffe0 55%,   /* Lighter yellow */
                #fad0c4 70%,   /* Lighter peach */
                #ff9a9e 80%,    /* Lighter pink */
                #fbc2eb 90%   /* Lighter purple */
            );
            background-attachment: fixed;
            min-height: 100vh;
            margin: 0;
            padding: 0;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
        }

        /* Content Container */
        .content-container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
        }

        /* Article Card */
        .article-card {
            background: rgba(255, 255, 255, 0.85);
            border-radius: 15px;
            box-shadow: 0 8px 30px rgba(0, 0, 0, 0.1);
            backdrop-filter: blur(10px);
            padding: 40px;
            margin-bottom: 40px;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        /* Header Styling */
        .article-header {
            text-align: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 3px solid rgba(90, 74, 227, 0.2);
        }

        .article-header h1 {
            color: #5a4ae3;
            font-weight: 800;
            margin-bottom: 15px;
            position: relative;
            display: inline-block;
        }

        .article-header h1::after {
            content: '';
            position: absolute;
            bottom: -10px;
            left: 50%;
            transform: translateX(-50%);
            width: 150px;
            height: 4px;
            background: linear-gradient(90deg, #ff8c8c, #4a3ce6);
            border-radius: 2px;
        }

        .article-meta {
            color: #666;
            font-size: 0.95rem;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 20px;
            margin-top: 15px;
        }

        /* Video Container */
        .video-section {
            margin: 40px 0;
            background: rgba(0, 0, 0, 0.05);
            border-radius: 12px;
            padding: 25px;
            border: 2px dashed rgba(90, 74, 227, 0.2);
        }

        .video-wrapper {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 Aspect Ratio */
            height: 0;
            overflow: hidden;
            border-radius: 8px;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.2);
            background: #000;
        }

        .video-wrapper video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .video-caption {
            text-align: center;
            font-style: italic;
            color: #666;
            margin-top: 15px;
            font-size: 0.9rem;
        }

        /* Content Sections */
        .content-section {
            margin: 30px 0;
        }

        .content-section h2 {
            color: #5a4ae3;
            border-left: 4px solid #5a4ae3;
            padding-left: 15px;
            margin: 25px 0 15px 0;
            font-weight: 700;
        }

        .content-section h3 {
            color: #7a6ae6;
            margin: 20px 0 10px 0;
            font-weight: 600;
        }

        .content-section p {
            margin-bottom: 15px;
            text-align: justify;
        }

        .highlight-box {
            background: linear-gradient(135deg, rgba(154, 75, 255, 0.1), rgba(90, 125, 255, 0.1));
            border-left: 4px solid #5a4ae3;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }

        /* Mathematical Notation */
        .math-formula {
            background: rgba(30, 30, 30, 0.05);
            border: 1px solid rgba(0, 0, 0, 0.1);
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            font-family: 'Cambria Math', serif;
            font-size: 1.1rem;
            text-align: center;
            overflow-x: auto;
        }

        /* Code Block */
        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
        }

        /* Navigation Buttons */
        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid rgba(90, 74, 227, 0.2);
        }

        .nav-btn {
            display: inline-flex;
            align-items: center;
            padding: 12px 25px;
            background: linear-gradient(120deg, rgba(154, 75, 255, 0.7), rgba(90, 125, 255, 0.7));
            color: white;
            text-decoration: none;
            border-radius: 8px;
            font-weight: 600;
            transition: all 0.3s;
            border: none;
        }

        .nav-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 7px 15px rgba(0, 0, 0, 0.2);
            color: white;
            background: linear-gradient(120deg, rgba(154, 75, 255, 0.9), rgba(90, 125, 255, 0.9));
        }

        /* Inherit navbar and footer styles */
        .navbar {
            background: linear-gradient(120deg, #9a4bff, #5a7dff, #ff8cc6);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        }
        
        footer {
            background: linear-gradient(90deg, #9a4bff, #5a7dff);
            color: white;
            padding: 30px 0;
            margin-top: 40px;
            box-shadow: 0 -4px 15px rgba(0, 0, 0, 0.1);
        }

        /* Responsive */
        @media (max-width: 768px) {
            .content-container {
                padding: 10px;
            }
            
            .article-card {
                padding: 25px;
            }
            
            .nav-buttons {
                flex-direction: column;
                gap: 15px;
            }
            
            .nav-btn {
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-dark">
        <div class="container">
            <a class="navbar-brand" href="index.html">
                <span class="infinity-logo">∞</span>
                <span>Infinite Maths</span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="index.html"><i class="fas fa-home me-1"></i> Home</a></li>
                    <li class="nav-item"><a class="nav-link active" href="machine_learning.html"><i class="fas fa-brain me-1"></i> Machine Learning</a></li>
                    <li class="nav-item"><a class="nav-link" href="ml_topics.html"><span style="font-family: 'Cambria Math', serif;">∈</span><i class="fas me-1"></i> ML Topics</a></li>
                    <li class="nav-item"><a class="nav-link" href="binomial.html"><span style="font-family: 'Cambria Math', serif;">∫</span> Calculus</a></li>
                    <li class="nav-item"><a class="nav-link" href="geometry.html"><i class="fas fa-percent me-1"></i> Probability</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <div class="container my-5">
        <div class="content-container">
            <!-- Breadcrumb Navigation -->
            <nav aria-label="breadcrumb" class="mb-4">
                <ol class="breadcrumb">
                    <li class="breadcrumb-item"><a href="index.html">Home</a></li>
                    <li class="breadcrumb-item"><a href="machine_learning.html">Machine Learning</a></li>
                    <li class="breadcrumb-item"><a href="ml_topics.html">ML Topics</a></li>
                    <li class="breadcrumb-item active" aria-current="page">Matrix Calculus</li>
                </ol>
            </nav>

            <div class="article-card">
                <!-- Article Header -->
                <div class="article-header">
                    <h1>Matrix Calculus in Machine Learning</h1>
                    <p class="lead">Understanding gradient computation for neural network optimization</p>
                    <div class="article-meta">
                        <span><i class="far fa-clock me-1"></i> 15 min read</span>
                        <span><i class="far fa-calendar me-1"></i> March 15, 2024</span>
                        <span><i class="fas fa-tag me-1"></i> Advanced</span>
                    </div>
                </div>

                <!-- Introduction Section -->
                <div class="content-section">
                    <p>Matrix calculus forms the mathematical backbone of modern deep learning. When training neural networks, we need to compute gradients of loss functions with respect to thousands or millions of parameters. Efficient gradient computation through matrix operations enables training of complex models.</p>
                    
                    <div class="highlight-box">
                        <p><strong>Key Insight:</strong> Matrix calculus allows us to compute derivatives of vector-valued functions with respect to vector or matrix inputs, which is essential for backpropagation in neural networks.</p>
                    </div>
                </div>

                <!-- Video Visualization Section -->
                <div class="content-section">
                    <h2><i class="fas fa-play-circle me-2"></i>Visual Explanation</h2>
                    <p>Watch this animation that demonstrates how gradients flow through matrix operations during backpropagation:</p>
                    
                    <div class="video-section">
                        <div class="video-wrapper">
                            <!-- Replace with your MP4 video -->
                            <video controls poster="images/matrix_calc_preview.jpg">
                                <source src="videos/matrix_calculus_animation.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                        </div>
                        <div class="video-caption">
                            Animation showing gradient computation in a simple neural network with two layers.
                            The colors represent different gradient magnitudes flowing backward through the network.
                        </div>
                    </div>
                    
                    <p>This visualization shows how partial derivatives propagate from the loss function back through each layer. Notice how the gradient magnitudes change as they pass through activation functions and matrix multiplications.</p>
                </div>

                <!-- Mathematical Explanation -->
                <div class="content-section">
                    <h2><i class="fas fa-square-root-alt me-2"></i>Mathematical Foundation</h2>
                    
                    <h3>Gradient of Matrix Multiplication</h3>
                    <p>Consider a simple linear layer without activation: <strong>y = Wx + b</strong>, where:</p>
                    <ul>
                        <li><strong>W</strong> is an m×n weight matrix</li>
                        <li><strong>x</strong> is an n-dimensional input vector</li>
                        <li><strong>b</strong> is an m-dimensional bias vector</li>
                    </ul>
                    
                    <div class="math-formula">
                        <p>For loss function L, the gradient with respect to W is:</p>
                        <p>∂L/∂W = (∂L/∂y) · x<sup>T</sup></p>
                        <p>where ∂L/∂y is the gradient from the next layer, and x<sup>T</sup> is the transpose of input x.</p>
                    </div>
                    
                    <h3>Chain Rule in Matrix Form</h3>
                    <p>The chain rule for matrix calculus follows a specific pattern. For composition f(g(x)), where g: ℝⁿ → ℝᵐ and f: ℝᵐ → ℝᵖ:</p>
                    
                    <div class="math-formula">
                        <p>∂f/∂x = ∂f/∂g · ∂g/∂x</p>
                        <p>Note that ∂g/∂x is an m×n Jacobian matrix, and ∂f/∂g is a p×m Jacobian matrix.</p>
                    </div>
                </div>

                <!-- Code Example -->
                <div class="content-section">
                    <h2><i class="fas fa-code me-2"></i>Python Implementation</h2>
                    <p>Here's a simple implementation of gradient computation for a two-layer neural network using NumPy:</p>
                    
                    <div class="code-block">
import numpy as np

def matrix_calculus_example():
    # Initialize parameters
    np.random.seed(42)
    W1 = np.random.randn(3, 4)  # 3x4 weight matrix
    W2 = np.random.randn(4, 2)  # 4x2 weight matrix
    x = np.random.randn(3, 1)   # 3x1 input vector
    y_true = np.array([[1], [0]])  # True labels
    
    # Forward pass
    z1 = W1 @ x
    a1 = np.tanh(z1)  # Activation
    z2 = W2 @ a1
    y_pred = 1 / (1 + np.exp(-z2))  # Sigmoid
    
    # Compute loss (binary cross-entropy)
    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))
    
    # Backward pass (gradient computation)
    dL_dy_pred = (y_pred - y_true) / y_pred.shape[0]
    dL_dz2 = dL_dy_pred * y_pred * (1 - y_pred)  # Sigmoid derivative
    dL_dW2 = dL_dz2 @ a1.T  # Gradient for W2
    
    dL_da1 = W2.T @ dL_dz2
    dL_dz1 = dL_da1 * (1 - a1**2)  # tanh derivative
    dL_dW1 = dL_dz1 @ x.T  # Gradient for W1
    
    return loss, dL_dW1, dL_dW2

# Run the example
loss, grad_W1, grad_W2 = matrix_calculus_example()
print(f"Loss: {loss:.4f}")
print(f"Gradient W1 shape: {grad_W1.shape}")
print(f"Gradient W2 shape: {grad_W2.shape}")
                    </div>
                    
                    <p>This code demonstrates the practical application of matrix calculus in computing gradients for a simple neural network. The key insight is that gradients are computed using matrix multiplications rather than element-wise operations.</p>
                </div>

                <!-- Applications Section -->
                <div class="content-section">
                    <h2><i class="fas fa-rocket me-2"></i>Applications in ML</h2>
                    
                    <div class="row mt-4">
                        <div class="col-md-6 mb-3">
                            <div class="card h-100">
                                <div class="card-body">
                                    <h5 class="card-title"><i class="fas fa-network-wired me-2"></i> Backpropagation</h5>
                                    <p class="card-text">Matrix calculus enables efficient computation of gradients in deep neural networks through the backpropagation algorithm, allowing training of models with millions of parameters.</p>
                                </div>
                            </div>
                        </div>
                        <div class="col-md-6 mb-3">
                            <div class="card h-100">
                                <div class="card-body">
                                    <h5 class="card-title"><i class="fas fa-robot me-2"></i> Optimization</h5>
                                    <p class="card-text">Optimization algorithms like gradient descent, Adam, and RMSprop rely on matrix gradients to update parameters in the direction that minimizes the loss function.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Summary Section -->
                <div class="content-section">
                    <h2><i class="fas fa-check-circle me-2"></i>Key Takeaways</h2>
                    <ul>
                        <li>Matrix calculus extends ordinary calculus to handle derivatives of matrices and vectors</li>
                        <li>Gradients in neural networks are computed using matrix multiplications rather than scalar operations</li>
                        <li>The chain rule applies in matrix form but requires careful attention to dimensions and transpositions</li>
                        <li>Efficient matrix gradient computation enables training of large-scale deep learning models</li>
                        <li>Understanding matrix calculus is essential for implementing custom layers or loss functions</li>
                    </ul>
                </div>

                <!-- Navigation Buttons -->
                <div class="nav-buttons">
                    <a href="ml_topics.html" class="nav-btn">
                        <i class="fas fa-arrow-left me-2"></i> Back to Topics
                    </a>
                    <a href="activation_functions.html" class="nav-btn">
                        Next: Activation Functions <i class="fas fa-arrow-right ms-2"></i>
                    </a>
                </div>
            </div>
        </div>
    </div>

    <footer class="text-center mt-5">
        <div class="container">
            <div class="mb-3">
                <i class="fas fa-calculator fa-2x mb-2"></i>
                <h4>Infinite Maths | Matrix Calculus</h4>
            </div>
            <div class="d-flex justify-content-center align-items-center">
                <a href="https://t.me/Kiara_infinita" class="text-decoration-none d-flex align-items-center" style="color: inherit;">
                    <span class="me-2">by Kiara Infinita | Contact me in Telegram</span>
                    <i class="fa-brands fa-telegram"></i>
                </a>
            </div>
        </div>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Animate article header
            const header = document.querySelector('.article-header h1');
            header.style.opacity = '0';
            header.style.transform = 'translateY(20px)';
            
            setTimeout(() => {
                header.style.transition = 'opacity 1s, transform 1s';
                header.style.opacity = '1';
                header.style.transform = 'translateY(0)';
            }, 300);
            
            // Add interactive elements to video
            const video = document.querySelector('video');
            if (video) {
                video.addEventListener('play', function() {
                    console.log('Matrix calculus animation started');
                });
                
                video.addEventListener('ended', function() {
                    console.log('Animation completed');
                });
            }
            
            // Smooth scroll for in-page links
            document.querySelectorAll('a[href^="#"]').forEach(anchor => {
                anchor.addEventListener('click', function(e) {
                    e.preventDefault();
                    const targetId = this.getAttribute('href');
                    if (targetId === '#') return;
                    
                    const targetElement = document.querySelector(targetId);
                    if (targetElement) {
                        window.scrollTo({
                            top: targetElement.offsetTop - 80,
                            behavior: 'smooth'
                        });
                    }
                });
            });
            
            // Add copy button to code blocks (optional enhancement)
            const codeBlocks = document.querySelectorAll('.code-block');
            codeBlocks.forEach((block, index) => {
                const copyButton = document.createElement('button');
                copyButton.innerHTML = '<i class="far fa-copy"></i> Copy';
                copyButton.className = 'btn btn-sm btn-dark position-absolute';
                copyButton.style.top = '10px';
                copyButton.style.right = '10px';
                copyButton.style.opacity = '0.8';
                copyButton.style.zIndex = '10';
                
                copyButton.addEventListener('click', function() {
                    const codeText = block.innerText;
                    navigator.clipboard.writeText(codeText).then(() => {
                        const originalText = copyButton.innerHTML;
                        copyButton.innerHTML = '<i class="fas fa-check"></i> Copied!';
                        setTimeout(() => {
                            copyButton.innerHTML = originalText;
                        }, 2000);
                    });
                });
                
                // Add relative positioning to the code block
                block.style.position = 'relative';
                block.appendChild(copyButton);
            });
        });
    </script>
</body>
</html>
